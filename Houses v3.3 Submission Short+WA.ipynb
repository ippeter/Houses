{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression, LinearRegression, SGDRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Helpers\n",
    "#\n",
    "def write_to_submission_file(predicted_labels, sale_ids, out_file=\"submission.csv\", target='SalePrice', index_label=\"Id\"):\n",
    "    \n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = sale_ids,\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "# Load House train & test data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Put the labels aside\n",
    "labels_orig = train.SalePrice.as_matrix().reshape(-1, 1)\n",
    "\n",
    "# This will be needed after pre-processing\n",
    "size_of_train = train.shape[0]\n",
    "print(size_of_train)\n",
    "\n",
    "# Merge datasets\n",
    "del train['SalePrice']\n",
    "\n",
    "train = pd.concat([train, test])\n",
    "\n",
    "# Define variables\n",
    "cols = []\n",
    "cols_count = 0\n",
    "\n",
    "# Handling years as categorial \n",
    "use_fe_2 = False\n",
    "\n",
    "# Using kind of a total sum of square feet\n",
    "use_fe_3 = True\n",
    "\n",
    "# Using new feature of Clustering\n",
    "use_fe_4 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MSSubClass\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "features = enc.fit_transform(train.MSSubClass.values.reshape(-1, 1))\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# MSZoning\n",
    "#train.MSZoning.fillna(\"RM\", inplace=True)\n",
    "train.MSZoning.fillna(\"Unknown\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.MSZoning).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# LotFrontage\n",
    "train.LotFrontage.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.LotFrontage.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# LotArea\n",
    "features = np.concatenate( [features, train.LotArea.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Street\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Street).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Alley\n",
    "train.Alley.fillna(\"NA\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Alley).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# LotShape\n",
    "features = np.concatenate( [features, pd.get_dummies(train.LotShape).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# LandContour\n",
    "features = np.concatenate( [features, pd.get_dummies(train.LandContour).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "#train.Utilities.fillna(\"AllPub\", inplace=True)\n",
    "train.Utilities.fillna(\"Unknown\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Utilities).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# LotConfig\n",
    "features = np.concatenate( [features, pd.get_dummies(train.LotConfig).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# LandSlope\n",
    "features = np.concatenate( [features, pd.get_dummies(train.LandSlope).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Neighborhood \n",
    "features = np.concatenate( [features, pd.get_dummies(train.Neighborhood).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Condition1\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Condition1).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Condition2\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Condition2).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BldgType\n",
    "features = np.concatenate( [features, pd.get_dummies(train.BldgType).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# HouseStyle\n",
    "features = np.concatenate( [features, pd.get_dummies(train.HouseStyle).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# OverallQual\n",
    "#enc = OneHotEncoder(sparse=False)\n",
    "#features = np.concatenate( [features, enc.fit_transform(train.OverallQual.values.reshape(-1, 1))], axis=1 )\n",
    "features = np.concatenate( [features, train.OverallQual.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# OverallCond\n",
    "#enc = OneHotEncoder(sparse=False)\n",
    "#features = np.concatenate( [features, enc.fit_transform(train.OverallCond.values.reshape(-1, 1))], axis=1 )\n",
    "features = np.concatenate( [features, train.OverallCond.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YearBuilt\n",
    "train['HouseAge'] = train.YrSold - train.YearBuilt\n",
    "features = np.concatenate( [features, train.HouseAge.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# YearRemodAdd\n",
    "train['AgeSinceRemod'] = train.YrSold - train.YearRemodAdd\n",
    "features = np.concatenate( [features, train.AgeSinceRemod.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# RoofStyle\n",
    "features = np.concatenate( [features, pd.get_dummies(train.RoofStyle).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# RoofMatl\n",
    "features = np.concatenate( [features, pd.get_dummies(train.RoofMatl).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Exterior1st\n",
    "#train.Exterior1st.fillna(\"Wd Sdng\", inplace=True)\n",
    "train.Exterior1st.fillna(\"Unknown\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Exterior1st).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Exterior2nd\n",
    "#train.Exterior2nd.fillna(\"Wd Sdng\", inplace=True)\n",
    "train.Exterior2nd.fillna(\"Unknown\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Exterior2nd).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# MasVnrType\n",
    "#train.MasVnrType.fillna(\"None\", inplace=True)\n",
    "train.MasVnrType.fillna(\"Unknown\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.MasVnrType).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# MasVnrArea\n",
    "train.MasVnrArea.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.MasVnrArea.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# ExterQual\n",
    "di = {\"Ex\": 5.0, \"Gd\": 4.0, \"TA\": 3.0, \"Fa\": 2.0, \"Po\": 1.0}\n",
    "train[\"ExterQual\"].replace(di, inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.ExterQual).as_matrix()], axis=1 )\n",
    "features = np.concatenate( [features, train.ExterQual.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# ExterCond\n",
    "di = {\"Ex\": 5.0, \"Gd\": 4.0, \"TA\": 3.0, \"Fa\": 2.0, \"Po\": 1.0}\n",
    "train[\"ExterCond\"].replace(di, inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.ExterCond).as_matrix()], axis=1 )\n",
    "features = np.concatenate( [features, train.ExterCond.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Foundation\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Foundation).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtQual\n",
    "train.BsmtQual.fillna(\"NA\", inplace=True)\n",
    "di = {\"Ex\": 5.0, \"Gd\": 4.0, \"TA\": 3.0, \"Fa\": 2.0, \"Po\": 1.0, \"NA\": 0.0}\n",
    "train[\"BsmtQual\"].replace(di, inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.BsmtQual).as_matrix()], axis=1 )\n",
    "features = np.concatenate( [features, train.BsmtQual.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtCond\n",
    "train.BsmtCond.fillna(\"NA\", inplace=True)\n",
    "di = {\"Ex\": 5.0, \"Gd\": 4.0, \"TA\": 3.0, \"Fa\": 2.0, \"Po\": 1.0, \"NA\": 0.0}\n",
    "train[\"BsmtCond\"].replace(di, inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.BsmtCond).as_matrix()], axis=1 )\n",
    "features = np.concatenate( [features, train.BsmtCond.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtExposure\n",
    "train.BsmtExposure.fillna(\"NA\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.BsmtExposure).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtFinType1\n",
    "train.BsmtFinType1.fillna(\"NA\", inplace=True)\n",
    "di = {\"GLQ\": 6.0, \"ALQ\": 5.0, \"BLQ\": 4.0, \"Rec\": 3.0, \"LwQ\": 2.0, \"Unf\": 1.0, \"NA\": 0.0}\n",
    "train[\"BsmtFinType1\"].replace(di, inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.BsmtFinType1).as_matrix()], axis=1 )\n",
    "features = np.concatenate( [features, train.BsmtFinType1.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtFinSF1\n",
    "train.BsmtFinSF1.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.BsmtFinSF1.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtFinType2\n",
    "train.BsmtFinType2.fillna(\"NA\", inplace=True)\n",
    "di = {\"GLQ\": 6.0, \"ALQ\": 5.0, \"BLQ\": 4.0, \"Rec\": 3.0, \"LwQ\": 2.0, \"Unf\": 1.0, \"NA\": 0.0}\n",
    "train[\"BsmtFinType2\"].replace(di, inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.BsmtFinType2).as_matrix()], axis=1 )\n",
    "features = np.concatenate( [features, train.BsmtFinType2.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtFinSF2\n",
    "train.BsmtFinSF2.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.BsmtFinSF2.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtUnfSF\n",
    "train.BsmtUnfSF.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.BsmtUnfSF.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# TotalBsmtSF\n",
    "train.TotalBsmtSF.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.TotalBsmtSF.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Heating\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Heating).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# HeatingQC\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.HeatingQC).as_matrix()], axis=1 )\n",
    "di = {\"Ex\": 5.0, \"Gd\": 4.0, \"TA\": 3.0, \"Fa\": 2.0, \"Po\": 1.0}\n",
    "train[\"HeatingQC\"].replace(di, inplace=True)\n",
    "features = np.concatenate( [features, train.HeatingQC.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# CentralAir\n",
    "features = np.concatenate( [features, pd.get_dummies(train.CentralAir).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Electrical\n",
    "train.Electrical.fillna(\"Unknown\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Electrical).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# 1stFlrSF\n",
    "features = np.concatenate( [features, train['1stFlrSF'].as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# 2ndFlrSF\n",
    "features = np.concatenate( [features, train['2ndFlrSF'].as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# LowQualFinSF\n",
    "features = np.concatenate( [features, train.LowQualFinSF.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# GrLivArea\n",
    "features = np.concatenate( [features, train.GrLivArea.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtFullBath\n",
    "train.BsmtFullBath.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.BsmtFullBath.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BsmtHalfBath\n",
    "train.BsmtHalfBath.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.BsmtHalfBath.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FullBath\n",
    "features = np.concatenate( [features, train.FullBath.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# HalfBath\n",
    "features = np.concatenate( [features, train.HalfBath.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# BedroomAbvGr\n",
    "features = np.concatenate( [features, train.BedroomAbvGr.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# KitchenAbvGr\n",
    "features = np.concatenate( [features, train.KitchenAbvGr.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# KitchenQual\n",
    "#train.KitchenQual.fillna(\"TA\", inplace=True)\n",
    "train.KitchenQual.fillna(\"Unknown\", inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.KitchenQual).as_matrix()], axis=1 )\n",
    "di = {\"Ex\": 5.0, \"Gd\": 4.0, \"TA\": 3.0, \"Fa\": 2.0, \"Po\": 1.0, \"Unknown\": 0.0}\n",
    "train[\"KitchenQual\"].replace(di, inplace=True)\n",
    "features = np.concatenate( [features, train.KitchenQual.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# TotRmsAbvGrd\n",
    "features = np.concatenate( [features, train.TotRmsAbvGrd.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Functional\n",
    "#train.Functional.fillna(\"Typ\", inplace=True)\n",
    "train.Functional.fillna(\"Unknown\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Functional).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Fireplaces\n",
    "features = np.concatenate( [features, train.Fireplaces.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# FireplaceQu\n",
    "train.FireplaceQu.fillna(\"NA\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.FireplaceQu).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# GarageType\n",
    "train.GarageType.fillna(\"NA\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.GarageType).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GarageYrBlt\n",
    "train.GarageYrBlt.fillna(train.YearBuilt, inplace=True)\n",
    "train['GarageAge'] = train.YrSold - train.GarageYrBlt\n",
    "features = np.concatenate( [features, train.GarageAge.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# GarageFinish\n",
    "train.GarageFinish.fillna(\"NA\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.GarageFinish).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# GarageCars\n",
    "train.GarageCars.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.GarageCars.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# GarageArea\n",
    "train.GarageArea.fillna(0.0, inplace=True)\n",
    "features = np.concatenate( [features, train.GarageArea.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# GarageQual\n",
    "train.GarageQual.fillna(\"NA\", inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.GarageQual).as_matrix()], axis=1 )\n",
    "di = {\"Ex\": 5.0, \"Gd\": 4.0, \"TA\": 3.0, \"Fa\": 2.0, \"Po\": 1.0, \"NA\": 0.0}\n",
    "train[\"GarageQual\"].replace(di, inplace=True)\n",
    "features = np.concatenate( [features, train.GarageQual.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# GarageCond\n",
    "train.GarageCond.fillna(\"NA\", inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.GarageCond).as_matrix()], axis=1 )\n",
    "di = {\"Ex\": 5.0, \"Gd\": 4.0, \"TA\": 3.0, \"Fa\": 2.0, \"Po\": 1.0, \"NA\": 0.0}\n",
    "train[\"GarageCond\"].replace(di, inplace=True)\n",
    "features = np.concatenate( [features, train.GarageCond.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# PavedDrive\n",
    "features = np.concatenate( [features, pd.get_dummies(train.PavedDrive).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# WoodDeckSF\n",
    "features = np.concatenate( [features, train.WoodDeckSF.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# OpenPorchSF\n",
    "features = np.concatenate( [features, train.OpenPorchSF.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# EnclosedPorch\n",
    "features = np.concatenate( [features, train.EnclosedPorch.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3SsnPorch\n",
    "features = np.concatenate( [features, train['3SsnPorch'].as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# ScreenPorch\n",
    "features = np.concatenate( [features, train.ScreenPorch.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# PoolArea\n",
    "features = np.concatenate( [features, train.PoolArea.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# PoolQC\n",
    "train.PoolQC.fillna(\"NA\", inplace=True)\n",
    "#features = np.concatenate( [features, pd.get_dummies(train.PoolQC).as_matrix()], axis=1 )\n",
    "di = {\"Ex\": 5.0, \"Gd\": 4.0, \"TA\": 3.0, \"Fa\": 2.0, \"Po\": 1.0, \"NA\": 0.0}\n",
    "train[\"PoolQC\"].replace(di, inplace=True)\n",
    "features = np.concatenate( [features, train.PoolQC.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# Fence\n",
    "train.Fence.fillna(\"NA\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.Fence).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# MiscFeature\n",
    "train.MiscFeature.fillna(\"NA\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.MiscFeature).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# MiscVal\n",
    "features = np.concatenate( [features, train.MiscVal.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# MoSold\n",
    "if (use_fe_2):\n",
    "    features = np.concatenate( [features, pd.get_dummies(train.MoSold).as_matrix()], axis=1 )\n",
    "else:\n",
    "    features = np.concatenate( [features, train.MoSold.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "    \n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# YrSold\n",
    "if (use_fe_2):\n",
    "    features = np.concatenate( [features, pd.get_dummies(train.YrSold).as_matrix()], axis=1 )\n",
    "else:\n",
    "    features = np.concatenate( [features, train.YrSold.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "    \n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# SaleType\n",
    "#train.SaleType.fillna(\"WD\", inplace=True)\n",
    "train.SaleType.fillna(\"Unknown\", inplace=True)\n",
    "features = np.concatenate( [features, pd.get_dummies(train.SaleType).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1\n",
    "\n",
    "# SaleCondition\n",
    "features = np.concatenate( [features, pd.get_dummies(train.SaleCondition).as_matrix()], axis=1 )\n",
    "cols_count = cols_count + 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LivingAreaSF\n",
    "if (use_fe_3):\n",
    "    train['LivingAreaSF'] = train['1stFlrSF'] + train['2ndFlrSF'] + train['TotalBsmtSF'] + \\\n",
    "                            train['GarageArea'] + train['MasVnrArea'] + train['WoodDeckSF'] + \\\n",
    "                            train['OpenPorchSF'] + train['3SsnPorch'] + train['ScreenPorch']\n",
    "\n",
    "    features = np.concatenate( [features, train.LivingAreaSF.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "    cols_count = cols_count + 1\n",
    "    \n",
    "    train['LandRatio'] = train['LivingAreaSF'] / train['LotArea']\n",
    "    features = np.concatenate( [features, train.LandRatio.as_matrix().reshape(-1, 1)], axis=1 )\n",
    "    cols_count = cols_count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 24 features scaled\n"
     ]
    }
   ],
   "source": [
    "# Prepare labels\n",
    "#labels = (train.SalePrice - train.MiscVal).values.reshape(-1, 1)\n",
    "labels = labels_orig\n",
    "\n",
    "# First scale labels\n",
    "labels = labels.astype(float)\n",
    "labels_max = labels.max()\n",
    "\n",
    "labels = labels / labels_max\n",
    "\n",
    "count = 0\n",
    "    \n",
    "for jj in range(features.shape[1]):\n",
    "    if((features[:, jj] > 25.).sum() > 0):\n",
    "        mx = float(features[:, jj].max())\n",
    "\n",
    "        features[:, jj] = features[:, jj] / mx\n",
    "        count = count + 1\n",
    "        \n",
    "print(\"Total\", count, \"features scaled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка наборов для обучения и тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features processed: 81\n",
      "\n",
      "(1460, 280)\n",
      "(1460, 1)\n",
      "(1459, 280)\n"
     ]
    }
   ],
   "source": [
    "# Split for train and test sets\n",
    "features_train = features[:size_of_train, :]\n",
    "labels_train = labels\n",
    "features_test = features[size_of_train:, :]\n",
    "\n",
    "print(\"Total features processed:\", cols_count)\n",
    "print(\"\")\n",
    "print(features_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Selection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# For Averaging\n",
    "#\n",
    "results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0205232781156\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def choose_LGB(X, y):\n",
    "    LGB = lgb.LGBMRegressor(random_state=23, n_jobs=-1)\n",
    "\n",
    "    parameters_grid = {\n",
    "        #\"boosting_type\": [\"gbdt\", \"dart\", \"goss\", \"rf\"],\n",
    "        \"n_estimators\": [50, 100, 150, 200, 250, 300, 350],\n",
    "        \"max_depth\": [2, 3, 4, 5, 6],\n",
    "        \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1],\n",
    "    }\n",
    "\n",
    "    gcv = GridSearchCV(LGB, parameters_grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    gcv.fit(X, y.reshape(-1))\n",
    "\n",
    "    print(gcv.best_score_)\n",
    "    print(gcv.best_params_)\n",
    "    \n",
    "    return gcv.best_estimator_    \n",
    "\n",
    "\n",
    "LGB = choose_LGB(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00880652030721 72\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "\n",
    "tmp_f = np.array(features_train)\n",
    "tmp_l = np.array(labels_train)\n",
    "\n",
    "for i in range(73):\n",
    "    LGB.fit(tmp_f, tmp_l.reshape(-1))\n",
    "    prediction = LGB.predict(tmp_f).reshape(-1, 1)\n",
    "\n",
    "    res.append(mean_absolute_error(tmp_l, prediction))\n",
    "    \n",
    "    if (i == 72):\n",
    "        break\n",
    "\n",
    "    tmp1 = np.abs(tmp_l - prediction)\n",
    "    d = tmp1.argmax()\n",
    "\n",
    "    tmp_f = np.delete(tmp_f, d, 0)\n",
    "    tmp_l = np.delete(tmp_l, d, 0)\n",
    "    \n",
    "print(min(res), argmin(res))\n",
    "\n",
    "prediction = LGB.predict(features_test)\n",
    "\n",
    "results['LGB'] = prediction.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0202452826565\n",
      "{'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 600}\n"
     ]
    }
   ],
   "source": [
    "def choose_GBM(X, y):\n",
    "    GBR = GradientBoostingRegressor(random_state=23)\n",
    "\n",
    "    parameters_grid = {\n",
    "        #\"n_estimators\": [250, 300, 350, 400, 450, 500, 550, 600],\n",
    "        \"n_estimators\": [350, 400, 450, 500, 550, 600],\n",
    "        \"min_samples_split\": [2, 3, 4, 5, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 3, 4]\n",
    "    }\n",
    "\n",
    "    gcv = GridSearchCV(GBR, parameters_grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    gcv.fit(X, y.reshape(-1))\n",
    "\n",
    "    print(gcv.best_score_)\n",
    "    print(gcv.best_params_)\n",
    "    \n",
    "    return gcv.best_estimator_\n",
    "\n",
    "\n",
    "GBM = choose_GBM(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00490467338095 70\n",
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "\n",
    "tmp_f = np.array(features_train)\n",
    "tmp_l = np.array(labels_train)\n",
    "\n",
    "for i in range(75):\n",
    "    GBM.fit(tmp_f, tmp_l.reshape(-1))\n",
    "    prediction = GBM.predict(tmp_f).reshape(-1, 1)\n",
    "\n",
    "    res.append(mean_absolute_error(tmp_l, prediction))\n",
    "    \n",
    "    if (i == 70):\n",
    "        break\n",
    "\n",
    "    tmp1 = np.abs(tmp_l - prediction)\n",
    "    d = tmp1.argmax()\n",
    "\n",
    "    tmp_f = np.delete(tmp_f, d, 0)\n",
    "    tmp_l = np.delete(tmp_l, d, 0)\n",
    "    \n",
    "print(min(res), argmin(res))\n",
    "\n",
    "prediction = GBM.predict(features_test)\n",
    "\n",
    "results['GBM'] = prediction.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0231520228587\n",
      "{'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 700}\n",
      "Wall time: 25min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RFR = RandomForestRegressor(n_jobs=-1, random_state=23)\n",
    "\n",
    "parameters_grid = {\n",
    "    \"n_estimators\": [200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700],\n",
    "    \"min_samples_split\": [2, 3, 4, 5, 6],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "gcv = GridSearchCV(RFR, parameters_grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "gcv.fit(features_train, labels_train.reshape(-1))\n",
    "\n",
    "print(gcv.best_score_)\n",
    "print(gcv.best_params_)\n",
    "\n",
    "RFR = gcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00654207637137 73\n",
      "Wall time: 6min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "\n",
    "tmp_f = np.array(features_train)\n",
    "tmp_l = np.array(labels_train)\n",
    "\n",
    "for i in range(75):\n",
    "    RFR.fit(tmp_f, tmp_l.reshape(-1))\n",
    "    prediction = RFR.predict(tmp_f).reshape(-1, 1)\n",
    "\n",
    "    res.append(mean_absolute_error(tmp_l, prediction))\n",
    "    \n",
    "    if (i == 73):\n",
    "        break\n",
    "\n",
    "    tmp1 = np.abs(tmp_l - prediction)\n",
    "    d = tmp1.argmax()\n",
    "\n",
    "    tmp_f = np.delete(tmp_f, d, 0)\n",
    "    tmp_l = np.delete(tmp_l, d, 0)\n",
    "    \n",
    "print(min(res), argmin(res))\n",
    "\n",
    "prediction = RFR.predict(features_test)\n",
    "\n",
    "results['RF'] = prediction.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0226646722288\n",
      "{'alpha': 0.1, 'gamma': 0.0046415888336127772, 'kernel': 'polynomial'}\n"
     ]
    }
   ],
   "source": [
    "def choose_KernelRidge(X, y):\n",
    "    clf = KernelRidge()\n",
    "\n",
    "    parameters_grid = {\n",
    "        \"kernel\": ['polynomial', 'rbf'], \n",
    "        \"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n",
    "        \"gamma\": np.logspace(-3, 3, 10)    \n",
    "    }\n",
    "\n",
    "    gcv = GridSearchCV(clf, parameters_grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    gcv.fit(X, y.reshape(-1))\n",
    "\n",
    "    print(gcv.best_score_)\n",
    "    print(gcv.best_params_)\n",
    "    \n",
    "    return gcv.best_estimator_\n",
    "\n",
    "\n",
    "KRG = choose_KernelRidge(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00823247822089 74\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "\n",
    "tmp_f = np.array(features_train)\n",
    "tmp_l = np.array(labels_train)\n",
    "\n",
    "for i in range(75):\n",
    "    KRG.fit(tmp_f, tmp_l.reshape(-1))\n",
    "    prediction = KRG.predict(tmp_f).reshape(-1, 1)\n",
    "\n",
    "    res.append(mean_absolute_error(tmp_l, prediction))\n",
    "    \n",
    "    if (i == 74):\n",
    "        break\n",
    "\n",
    "    tmp1 = np.abs(tmp_l - prediction)\n",
    "    d = tmp1.argmax()\n",
    "\n",
    "    tmp_f = np.delete(tmp_f, d, 0)\n",
    "    tmp_l = np.delete(tmp_l, d, 0)\n",
    "    \n",
    "print(min(res), argmin(res))\n",
    "\n",
    "prediction = KRG.predict(features_test)\n",
    "\n",
    "results['KRG'] = prediction.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0202368960687\n",
      "{'max_depth': 2, 'n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "def choose_XGB(X, y):\n",
    "    XGB = xgboost.XGBRegressor()\n",
    "\n",
    "    parameters_grid = {\n",
    "        \"n_estimators\": [300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000],\n",
    "        #\"n_estimators\": [250, 300, 350],\n",
    "        #\"max_depth\": [2, 3, 4, 5, 6, 7, 8],\n",
    "        \"max_depth\": [2, 3, 4, 5],\n",
    "        #\"learning_rate\": [0.1, 0.05, 0.01]\n",
    "        #\"learning_rate\": [0.1],\n",
    "    }\n",
    "\n",
    "    gcv = GridSearchCV(XGB, parameters_grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    gcv.fit(X, y.reshape(-1))\n",
    "\n",
    "    print(gcv.best_score_)\n",
    "    print(gcv.best_params_)\n",
    "    \n",
    "    return gcv.best_estimator_\n",
    "\n",
    "\n",
    "XGB = choose_XGB(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00866033397388 73\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "\n",
    "tmp_f = np.array(features_train)\n",
    "tmp_l = np.array(labels_train)\n",
    "\n",
    "for i in range(75):\n",
    "    XGB.fit(tmp_f, tmp_l.reshape(-1))\n",
    "    prediction = XGB.predict(tmp_f).reshape(-1, 1)\n",
    "\n",
    "    res.append(mean_absolute_error(tmp_l, prediction))\n",
    "    \n",
    "    if (i == 73):\n",
    "        break\n",
    "\n",
    "    tmp1 = np.abs(tmp_l - prediction)\n",
    "    d = tmp1.argmax()\n",
    "\n",
    "    tmp_f = np.delete(tmp_f, d, 0)\n",
    "    tmp_l = np.delete(tmp_l, d, 0)\n",
    "    \n",
    "print(min(res), argmin(res))\n",
    "\n",
    "prediction = XGB.predict(features_test)\n",
    "\n",
    "results['XGB'] = prediction.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LGB</th>\n",
       "      <th>KRG</th>\n",
       "      <th>XGB</th>\n",
       "      <th>GBM</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.172551</td>\n",
       "      <td>0.158953</td>\n",
       "      <td>0.167144</td>\n",
       "      <td>0.163088</td>\n",
       "      <td>0.179363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211509</td>\n",
       "      <td>0.212709</td>\n",
       "      <td>0.218139</td>\n",
       "      <td>0.227571</td>\n",
       "      <td>0.209968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250716</td>\n",
       "      <td>0.236492</td>\n",
       "      <td>0.242999</td>\n",
       "      <td>0.249454</td>\n",
       "      <td>0.241507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.248756</td>\n",
       "      <td>0.257584</td>\n",
       "      <td>0.254926</td>\n",
       "      <td>0.264987</td>\n",
       "      <td>0.252983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.249427</td>\n",
       "      <td>0.244794</td>\n",
       "      <td>0.239664</td>\n",
       "      <td>0.235327</td>\n",
       "      <td>0.252389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LGB       KRG       XGB       GBM        RF\n",
       "0  0.172551  0.158953  0.167144  0.163088  0.179363\n",
       "1  0.211509  0.212709  0.218139  0.227571  0.209968\n",
       "2  0.250716  0.236492  0.242999  0.249454  0.241507\n",
       "3  0.248756  0.257584  0.254926  0.264987  0.252983\n",
       "4  0.249427  0.244794  0.239664  0.235327  0.252389"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = 0.3*results['KRG'] + 0.1*results['RF'] + 0.1*results['LGB'] + 0.2*results['GBM'] + 0.3*results['XGB']\n",
    "tmp = np.array(tmp.tolist())\n",
    "write_to_submission_file(tmp * labels_max, test.Id, out_file=\"submission.Short+WA.csv\", target='SalePrice', index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
